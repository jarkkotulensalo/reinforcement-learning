{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import cv2\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('obs', 'action', 'next_obs', 'reward', 'done'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def save_memory(self,savepath):\n",
    "        with open(savepath,'wb') as f:\n",
    "            pickle.dump(self.memory,f)\n",
    "\n",
    "    def load_memory(self, loadpath, loadpath2 = None):\n",
    "        with open(loadpath,'rb') as f:\n",
    "            transitions = pickle.load(f)\n",
    "            print(len(transitions))\n",
    "        if loadpath2 != None:\n",
    "            with open(loadpath2,'rb')as f:\n",
    "                transitions2 = pickle.load(f)\n",
    "                print(len(transitions2))\n",
    "                print(transitions2[0])\n",
    "            transitions = transitions+transitions2\n",
    "            print(len(transitions))\n",
    "        return transitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2261\n",
      "2048\n",
      "Transition(obs=tensor([[47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        ...,\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407]]), action=tensor([1]), next_obs=tensor([[47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        ...,\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407]]), reward=tensor([0.]), done=False)\n",
      "4309\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayMemory(100000)\n",
    "transitions = memory.load_memory('./mem7-3.pickle','./mem.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "#print(len(transitions))\n",
    "print(transitions[2500][0].numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        ...,\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407]])\n"
     ]
    }
   ],
   "source": [
    "img = transitions[99][2].numpy()\n",
    "print(torch.from_numpy(img).float())\n",
    "#def rgb2gray(rgb):\n",
    "#    return np.dot(rgb[:,:,:3], [0.2989, 0.5870, 0.1140])\n",
    "#img = rgb2gray(img)\n",
    "#print(img)\n",
    "#cv2.imwrite('color_img.jpg', img)\n",
    "#cv2.imshow(\"image\", img)\n",
    "#cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47.6407 47.6407 47.6407 ... 47.6407 47.6407 47.6407]\n",
      " [47.6407 47.6407 47.6407 ... 47.6407 47.6407 47.6407]\n",
      " [47.6407 47.6407 47.6407 ... 47.6407 47.6407 47.6407]\n",
      " ...\n",
      " [47.6407 47.6407 47.6407 ... 47.6407 47.6407 47.6407]\n",
      " [47.6407 47.6407 47.6407 ... 47.6407 47.6407 47.6407]\n",
      " [47.6407 47.6407 47.6407 ... 47.6407 47.6407 47.6407]]\n"
     ]
    }
   ],
   "source": [
    "img = transitions[99][2].numpy()\n",
    "print(img)\n",
    "#def rgb2gray(rgb):\n",
    "#    return np.dot(rgb[:,:,:3], [0.2989, 0.5870, 0.1140])\n",
    "#img = rgb2gray(img)\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "frame = cv2.cvtColor(np.uint8(transitions[0][0].numpy()), cv2.COLOR_BGR2RGB)\n",
    "frame = cv2.resize(frame, (235*1,\n",
    "                    200*1),\n",
    "                    interpolation=cv2.INTER_NEAREST)\n",
    "cv2.imshow('Wimblepong', frame)\n",
    "#cv2.waitKey(max(1000//30, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[:,:,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "img = transitions[0][0]  \n",
    "gray = rgb2gray(img)    \n",
    "plt.imshow(img, cmap=plt.get_cmap('rgb'), vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayMemory(100)\n",
    "for i in range(100):\n",
    "    ob1 = torch.rand(200,200,3)\n",
    "    action = torch.tensor([0])\n",
    "    ob1_next = torch.rand(200,200,3)\n",
    "    reward = torch.tensor([0.])\n",
    "    done = False\n",
    "    memory.push(ob1,action,ob1_next,reward,done)\n",
    "sample = memory.sample(3)    \n",
    "memory.pickle_rick('./mem.pickle')\n",
    "transitions = memory.load_pickle_rick('./mem.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDQN(nn.Module):\n",
    "    def __init__(self,input_channels, num_actions):\n",
    "        super(CNNDQN,self).__init__()\n",
    "        self.Conv1 = nn.Conv2d(1, 16, 5, stride=1)# 200->198\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)# 198->99\n",
    "        self.Conv2 = nn.Conv2d(16,32,5) #12->8 and second pool 8->4\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "        self.Linear1 = nn.Linear(32*100*100,64)#eli input channelit * imagesize * imagesize\n",
    "        self.ReLU3 = nn.ReLU()\n",
    "        self.Linear2 = nn.Linear(64,16)\n",
    "        self.ReLu4 = nn.ReLU()\n",
    "        self.Linear3 = nn.Linear(16,3)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        print(x.shape)\n",
    "        x = self.Conv1(x)\n",
    "        x = self.pool(self.ReLU1(x))\n",
    "        x = self.pool(self.ReLU2(self.Conv2(x)))\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = self.ReLU3(self.Linear1(x))\n",
    "        x = self.ReLu4(self.Linear2(x))\n",
    "        x = self.Linear3(x)\n",
    "        return x\n",
    "\n",
    "    #source \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNDQN(\n",
      "  (Conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (ReLU1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (Conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (ReLU2): ReLU()\n",
      "  (Linear1): Linear(in_features=320000, out_features=64, bias=True)\n",
      "  (ReLU3): ReLU()\n",
      "  (Linear2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (ReLu4): ReLU()\n",
      "  (Linear3): Linear(in_features=16, out_features=3, bias=True)\n",
      ")\n",
      "tensor([[47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        ...,\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407],\n",
      "        [47.6407, 47.6407, 47.6407,  ..., 47.6407, 47.6407, 47.6407]])\n",
      "torch.Size([200, 200])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight 16 1, but got 2-dimensional input of size [200, 200] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-627705316d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mDQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-60-876cad403307>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight 16 1, but got 2-dimensional input of size [200, 200] instead"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "DQN = CNNDQN(1,3).to(device)\n",
    "print(DQN)\n",
    "state_batch = torch.stack(transitions[0]).to(self.train_device)\n",
    "transition = transitions[0]\n",
    "frame = transition[0].to(device)\n",
    "print(frame)\n",
    "DQN.forward(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "glie_a = 500\n",
    "episodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = []\n",
    "for i in range(episodes):\n",
    "    #if i%2==0:\n",
    "    if i/episodes<0.5:\n",
    "        eps.append((glie_a)/(glie_a+i*2))\n",
    "    else:\n",
    "        eps.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04762811964183654\n"
     ]
    }
   ],
   "source": [
    "print(eps[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
